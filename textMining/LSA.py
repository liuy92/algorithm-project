#-*-coding:utf-8-*-



#LSA (LSI Latent Semantic Indexing) —— 潜在予以索引
"""
实质：基于SVD的简单实用的主题模型
原理：
    1. SVD 任意 m*n 矩阵可以通过矩阵分解的形式，分解为 A = U * amiga * V'
       在 LSA 中可以解释为。对于存在的 m 个文档，n 个有效词汇。假设存在 k 个主题
       通过SVD可以分解为
       U_il 代表第i个文本(样本)和第l个主题(降维后的第l维)的相关度
       V_jm 代表第j个词汇(特征)和第m个词义(降维后的第m维)的相关度
       amiga_lm 代表第l个主题和第m个词义的相关度
       通常是反过来解释文本和主题之间的关系
       由SVD的性质可以看到，在这种方式下，词义和主题是一一对应的（amigo是对角线矩阵）
    2. 而基于矩阵分解的结果，可以计算文本之间的相似度和词汇之间的相似度
       往往用过计算余弦相似度来评估
       sim(dj1, dj2) = sum_k(V[j1, i] * V[j2, i]) / sqrt(sum(V[j1, i] ** 2) * sum(V[j2, i] ** 2))
问题：
    1. 计算耗时 —— NMF解决
    2. k值难选 —— HDP选择
    3. 缺乏统计基础，结果难以解释
"""
